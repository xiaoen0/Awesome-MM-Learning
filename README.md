# Awesome-MM-Learning
## Image-Language
- **Minigpt-4: Enhancing vision-language understanding with advanced large language models** <br>
[ICLR 2023] [[paper](https://arxiv.org/abs/2304.10592)] [[project page](https://minigpt-4.github.io/)]
- **BLIP-2** <br>
[[paper](https://arxiv.org/abs/2301.12597)]
- **Rethinking Visual Prompting for Multimodal Large Language Models with External Knowledge** <br>
[[paper](https://arxiv.org/abs/2407.04681)]
- **Robust Multimodal Learning via Representation Decoupling** <br>
[[paper](https://arxiv.org/abs/2407.04458)] <br>

## Image-Video-Audio
- **PandaGPT: One Model To Instruction-Follow Them All** <br>
[TLLM 2023] [[paper](https://arxiv.org/abs/2305.16355)] [[project page](https://panda-gpt.github.io/)] [[code](https://github.com/yxuansu/PandaGPT)] <br>
**Image-Language Tasks**: image description generation <br>
**Video-Language Tasks**: writing stories inspired by videos <br>
**Audio-Language Tasks**: answering questions about audios
- **Enhance the Robustness in Text-Centric Multimodal Alignments** <br>
[[paper](https://arxiv.org/abs/2407.05036)] <br>







